{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics for dataset evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from notebook_init import notebook_init, notebook_imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_scores(fname):\n",
    "    scores = []\n",
    "    with open(fname) as f:\n",
    "        lines = f.readlines()\n",
    "        for l in lines:\n",
    "            l.strip('[]')\n",
    "            tmp = l.split(',')\n",
    "            scores_i = [ int(s.strip())  for s in tmp]\n",
    "            scores.append(scores_i)\n",
    "            \n",
    "    return scores\n",
    "                \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcualate_metrics(scores):\n",
    "    average_score_per_dialogue = [sum(s)/len(s) for s in scores]\n",
    "    total_average_score = sum(average_score_per_dialogue)/len(average_score_per_dialogue) \n",
    "    return average_score_per_dialogue, total_average_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Role fitness\n",
    "\n",
    "Scores for role fitness are given on a scale from 1 to 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average scores per dialogue: \n",
      "Dialogue  0 :  3.8333333333333335\n",
      "Dialogue  1 :  3.6666666666666665\n",
      "Dialogue  2 :  4.333333333333333\n",
      "Dialogue  3 :  4.0\n",
      "Dialogue  4 :  3.8333333333333335\n",
      "Dialogue  5 :  4.0\n",
      "Dialogue  6 :  4.166666666666667\n",
      "Dialogue  7 :  4.0\n",
      "Dialogue  8 :  4.0\n",
      "Dialogue  9 :  4.0\n",
      "Dialogue  10 :  4.0\n",
      "Dialogue  11 :  4.0\n",
      "Dialogue  12 :  4.666666666666667\n",
      "Dialogue  13 :  4.166666666666667\n",
      "Dialogue  14 :  4.0\n",
      "Dialogue  15 :  4.0\n",
      "Dialogue  16 :  4.166666666666667\n",
      "Dialogue  17 :  3.3333333333333335\n",
      "\n",
      "Total average score:  4.009259259259259\n"
     ]
    }
   ],
   "source": [
    "identity_pipeline_scores = load_scores('../../plays/evaluation/role_fitness/identity.csv')\n",
    "identity_pipeline_scores\n",
    "\n",
    "avg_dialogue_scores, total_avg = calcualate_metrics(identity_pipeline_scores)\n",
    "\n",
    "print('Average scores per dialogue: ')\n",
    "for i, s in enumerate(avg_dialogue_scores):\n",
    "    print('Dialogue ', i, ': ', s )\n",
    "\n",
    "print()\n",
    "print('Total average score: ', total_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average scores per dialogue: \n",
      "Dialogue  0 :  3.1666666666666665\n",
      "Dialogue  1 :  3.6666666666666665\n",
      "Dialogue  2 :  4.166666666666667\n",
      "Dialogue  3 :  3.3333333333333335\n",
      "Dialogue  4 :  4.5\n",
      "Dialogue  5 :  4.166666666666667\n",
      "Dialogue  6 :  4.0\n",
      "Dialogue  7 :  4.333333333333333\n",
      "Dialogue  8 :  4.833333333333333\n",
      "Dialogue  9 :  4.5\n",
      "Dialogue  10 :  4.0\n",
      "Dialogue  11 :  4.833333333333333\n",
      "Dialogue  12 :  4.166666666666667\n",
      "Dialogue  13 :  5.0\n",
      "Dialogue  14 :  4.166666666666667\n",
      "Dialogue  15 :  4.333333333333333\n",
      "Dialogue  16 :  4.5\n",
      "Dialogue  17 :  4.333333333333333\n",
      "\n",
      "Total average score:  4.222222222222222\n"
     ]
    }
   ],
   "source": [
    "role_fitness_0_scores = load_scores('../../plays/evaluation/role_fitness/rf_0.csv')\n",
    "\n",
    "avg_dialogue_scores, total_avg = calcualate_metrics(role_fitness_0_scores)\n",
    "\n",
    "print('Average scores per dialogue: ')\n",
    "for i, s in enumerate(avg_dialogue_scores):\n",
    "    print('Dialogue ', i, ': ', s )\n",
    "\n",
    "print()\n",
    "print('Total average score: ', total_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average scores per dialogue: \n",
      "Dialogue  0 :  4.0\n",
      "Dialogue  1 :  4.0\n",
      "Dialogue  2 :  4.0\n",
      "Dialogue  3 :  3.6666666666666665\n",
      "Dialogue  4 :  3.6666666666666665\n",
      "Dialogue  5 :  4.333333333333333\n",
      "Dialogue  6 :  4.166666666666667\n",
      "Dialogue  7 :  4.0\n",
      "Dialogue  8 :  4.0\n",
      "Dialogue  9 :  3.8333333333333335\n",
      "Dialogue  10 :  4.666666666666667\n",
      "Dialogue  11 :  4.333333333333333\n",
      "Dialogue  12 :  4.666666666666667\n",
      "Dialogue  13 :  4.666666666666667\n",
      "Dialogue  14 :  4.0\n",
      "Dialogue  15 :  4.666666666666667\n",
      "Dialogue  16 :  4.666666666666667\n",
      "Dialogue  17 :  4.833333333333333\n",
      "\n",
      "Total average score:  4.231481481481481\n"
     ]
    }
   ],
   "source": [
    "role_fitness_1_scores = load_scores('../../plays/evaluation/role_fitness/rf_1.csv')\n",
    "\n",
    "avg_dialogue_scores, total_avg = calcualate_metrics(role_fitness_1_scores)\n",
    "\n",
    "print('Average scores per dialogue: ')\n",
    "for i, s in enumerate(avg_dialogue_scores):\n",
    "    print('Dialogue ', i, ': ', s )\n",
    "\n",
    "print()\n",
    "print('Total average score: ', total_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average scores per dialogue: \n",
      "Dialogue  0 :  4.333333333333333\n",
      "Dialogue  1 :  4.0\n",
      "Dialogue  2 :  3.5\n",
      "Dialogue  3 :  4.0\n",
      "Dialogue  4 :  4.0\n",
      "Dialogue  5 :  4.333333333333333\n",
      "Dialogue  6 :  4.0\n",
      "Dialogue  7 :  3.1666666666666665\n",
      "Dialogue  8 :  3.8333333333333335\n",
      "Dialogue  9 :  4.5\n",
      "Dialogue  10 :  4.166666666666667\n",
      "Dialogue  11 :  4.833333333333333\n",
      "Dialogue  12 :  4.166666666666667\n",
      "Dialogue  13 :  4.5\n",
      "Dialogue  14 :  4.0\n",
      "Dialogue  15 :  4.166666666666667\n",
      "Dialogue  16 :  4.666666666666667\n",
      "Dialogue  17 :  4.0\n",
      "\n",
      "Total average score:  4.12037037037037\n"
     ]
    }
   ],
   "source": [
    "role_fitness_2_scores = load_scores('../../plays/evaluation/role_fitness/rf_2.csv')\n",
    "\n",
    "avg_dialogue_scores, total_avg = calcualate_metrics(role_fitness_2_scores)\n",
    "\n",
    "print('Average scores per dialogue: ')\n",
    "for i, s in enumerate(avg_dialogue_scores):\n",
    "    print('Dialogue ', i, ': ', s )\n",
    "\n",
    "print()\n",
    "print('Total average score: ', total_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average scores per dialogue: \n",
      "Dialogue  0 :  4.5\n",
      "Dialogue  1 :  4.0\n",
      "Dialogue  2 :  4.166666666666667\n",
      "Dialogue  3 :  4.166666666666667\n",
      "Dialogue  4 :  3.6666666666666665\n",
      "Dialogue  5 :  4.833333333333333\n",
      "Dialogue  6 :  4.166666666666667\n",
      "Dialogue  7 :  4.0\n",
      "Dialogue  8 :  4.333333333333333\n",
      "Dialogue  9 :  4.0\n",
      "Dialogue  10 :  4.333333333333333\n",
      "Dialogue  11 :  4.5\n",
      "Dialogue  12 :  4.666666666666667\n",
      "Dialogue  13 :  3.8333333333333335\n",
      "Dialogue  14 :  4.833333333333333\n",
      "Dialogue  15 :  4.833333333333333\n",
      "Dialogue  16 :  4.666666666666667\n",
      "Dialogue  17 :  4.166666666666667\n",
      "\n",
      "Total average score:  4.314814814814815\n"
     ]
    }
   ],
   "source": [
    "role_fitness_3_scores = load_scores('../../plays/evaluation/role_fitness/rf_3.csv')\n",
    "\n",
    "avg_dialogue_scores, total_avg = calcualate_metrics(role_fitness_3_scores)\n",
    "\n",
    "print('Average scores per dialogue: ')\n",
    "for i, s in enumerate(avg_dialogue_scores):\n",
    "    print('Dialogue ', i, ': ', s )\n",
    "\n",
    "print()\n",
    "print('Total average score: ', total_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average scores per dialogue: \n",
      "Dialogue  0 :  3.0\n",
      "Dialogue  1 :  3.6666666666666665\n",
      "Dialogue  2 :  3.5\n",
      "Dialogue  3 :  4.0\n",
      "Dialogue  4 :  4.5\n",
      "Dialogue  5 :  4.0\n",
      "Dialogue  6 :  4.333333333333333\n",
      "Dialogue  7 :  4.0\n",
      "Dialogue  8 :  4.0\n",
      "Dialogue  9 :  4.0\n",
      "Dialogue  10 :  4.166666666666667\n",
      "Dialogue  11 :  4.166666666666667\n",
      "Dialogue  12 :  4.833333333333333\n",
      "Dialogue  13 :  4.5\n",
      "Dialogue  14 :  4.0\n",
      "Dialogue  15 :  4.833333333333333\n",
      "Dialogue  16 :  4.0\n",
      "Dialogue  17 :  4.0\n",
      "\n",
      "Total average score:  4.083333333333333\n"
     ]
    }
   ],
   "source": [
    "ll_rf_0 = load_scores('../../plays/evaluation/role_fitness/ll_rf_0.csv')\n",
    "\n",
    "avg_dialogue_scores, total_avg = calcualate_metrics(ll_rf_0)\n",
    "\n",
    "avg_scores_per_ll = []\n",
    "for i in range(0, 18, 3):\n",
    "    avg_scores_per_ll.append(sum(avg_dialogue_scores[i:i+3])/3)\n",
    "\n",
    "print('Average scores per dialogue: ')\n",
    "for i, s in enumerate(avg_dialogue_scores):\n",
    "    print('Dialogue ', i, ': ', s )\n",
    "\n",
    "\n",
    "print()\n",
    "print('Total average score: ', total_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average scores per dialogue: \n",
      "Dialogue  0 :  2.8333333333333335\n",
      "Dialogue  1 :  3.5\n",
      "Dialogue  2 :  3.5\n",
      "Dialogue  3 :  4.0\n",
      "Dialogue  4 :  4.333333333333333\n",
      "Dialogue  5 :  4.166666666666667\n",
      "Dialogue  6 :  3.8333333333333335\n",
      "Dialogue  7 :  4.166666666666667\n",
      "Dialogue  8 :  3.8333333333333335\n",
      "Dialogue  9 :  4.5\n",
      "Dialogue  10 :  4.166666666666667\n",
      "Dialogue  11 :  4.166666666666667\n",
      "Dialogue  12 :  4.0\n",
      "Dialogue  13 :  4.666666666666667\n",
      "Dialogue  14 :  4.666666666666667\n",
      "Dialogue  15 :  4.333333333333333\n",
      "Dialogue  16 :  3.6666666666666665\n",
      "Dialogue  17 :  4.833333333333333\n",
      "\n",
      "Total average score:  4.064814814814814\n"
     ]
    }
   ],
   "source": [
    "ll_rf_1 = load_scores('../../plays/evaluation/role_fitness/ll_rf_1.csv')\n",
    "\n",
    "avg_dialogue_scores, total_avg = calcualate_metrics(ll_rf_1)\n",
    "\n",
    "avg_scores_per_ll = []\n",
    "for i in range(0, 18, 3):\n",
    "    avg_scores_per_ll.append(sum(avg_dialogue_scores[i:i+3])/3)\n",
    "\n",
    "print('Average scores per dialogue: ')\n",
    "for i, s in enumerate(avg_dialogue_scores):\n",
    "    print('Dialogue ', i, ': ', s )\n",
    "\n",
    "\n",
    "print()\n",
    "print('Total average score: ', total_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average scores per dialogue: \n",
      "Dialogue  0 :  4.166666666666667\n",
      "Dialogue  1 :  4.166666666666667\n",
      "Dialogue  2 :  4.0\n",
      "Dialogue  3 :  4.0\n",
      "Dialogue  4 :  4.166666666666667\n",
      "Dialogue  5 :  3.5\n",
      "Dialogue  6 :  4.166666666666667\n",
      "Dialogue  7 :  3.3333333333333335\n",
      "Dialogue  8 :  4.166666666666667\n",
      "Dialogue  9 :  4.333333333333333\n",
      "Dialogue  10 :  4.166666666666667\n",
      "Dialogue  11 :  4.166666666666667\n",
      "Dialogue  12 :  3.8333333333333335\n",
      "Dialogue  13 :  4.333333333333333\n",
      "Dialogue  14 :  4.0\n",
      "Dialogue  15 :  4.666666666666667\n",
      "Dialogue  16 :  4.333333333333333\n",
      "Dialogue  17 :  3.8333333333333335\n",
      "\n",
      "Total average score:  4.0740740740740735\n"
     ]
    }
   ],
   "source": [
    "ll_rf_2 = load_scores('../../plays/evaluation/role_fitness/ll_rf_2.csv')\n",
    "\n",
    "avg_dialogue_scores, total_avg = calcualate_metrics(ll_rf_2)\n",
    "\n",
    "avg_scores_per_ll = []\n",
    "for i in range(0, 18, 3):\n",
    "    avg_scores_per_ll.append(sum(avg_dialogue_scores[i:i+3])/3)\n",
    "\n",
    "print('Average scores per dialogue: ')\n",
    "for i, s in enumerate(avg_dialogue_scores):\n",
    "    print('Dialogue ', i, ': ', s )\n",
    "\n",
    "print()\n",
    "print('Total average score: ', total_avg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Language level \n",
    "\n",
    "Scores for language level are given on a scale from 1 to 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average scores per dialogue: \n",
      "Dialogue  0 :  1.6666666666666667\n",
      "Dialogue  1 :  2.0\n",
      "Dialogue  2 :  1.3333333333333333\n",
      "Dialogue  3 :  3.0\n",
      "Dialogue  4 :  2.6666666666666665\n",
      "Dialogue  5 :  2.8333333333333335\n",
      "Dialogue  6 :  3.0\n",
      "Dialogue  7 :  2.1666666666666665\n",
      "Dialogue  8 :  2.1666666666666665\n",
      "Dialogue  9 :  2.3333333333333335\n",
      "Dialogue  10 :  2.6666666666666665\n",
      "Dialogue  11 :  2.5\n",
      "Dialogue  12 :  2.8333333333333335\n",
      "Dialogue  13 :  2.5\n",
      "Dialogue  14 :  2.3333333333333335\n",
      "Dialogue  15 :  2.3333333333333335\n",
      "Dialogue  16 :  2.5\n",
      "Dialogue  17 :  2.5\n",
      "\n",
      "Average score per language level\n",
      "Level  A1 :  1.6666666666666667\n",
      "Level  A2 :  2.8333333333333335\n",
      "Level  B1 :  2.444444444444444\n",
      "Level  B2 :  2.5\n",
      "Level  C1 :  2.555555555555556\n",
      "Level  C2 :  2.4444444444444446\n",
      "\n",
      "Total average score:  2.407407407407408\n"
     ]
    }
   ],
   "source": [
    "identity_pipeline_scores_ll = load_scores('../../plays/evaluation/language_level/identity.csv')\n",
    "\n",
    "avg_dialogue_scores, total_avg = calcualate_metrics(identity_pipeline_scores_ll)\n",
    "\n",
    "avg_scores_per_ll = []\n",
    "for i in range(0, 18, 3):\n",
    "    avg_scores_per_ll.append(sum(avg_dialogue_scores[i:i+3])/3)\n",
    "\n",
    "print('Average scores per dialogue: ')\n",
    "for i, s in enumerate(avg_dialogue_scores):\n",
    "    print('Dialogue ', i, ': ', s )\n",
    "    \n",
    "print()\n",
    "print('Average score per language level')\n",
    "\n",
    "for s, ll in zip(avg_scores_per_ll, ['A1', 'A2', 'B1', 'B2', 'C1', 'C2']):\n",
    "    print('Level ', ll, ': ', s )\n",
    "\n",
    "print()\n",
    "print('Total average score: ', total_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average scores per dialogue: \n",
      "Dialogue  0 :  2.0\n",
      "Dialogue  1 :  2.5\n",
      "Dialogue  2 :  2.8333333333333335\n",
      "Dialogue  3 :  2.0\n",
      "Dialogue  4 :  2.5\n",
      "Dialogue  5 :  2.0\n",
      "Dialogue  6 :  2.8333333333333335\n",
      "Dialogue  7 :  2.8333333333333335\n",
      "Dialogue  8 :  2.5\n",
      "Dialogue  9 :  2.6666666666666665\n",
      "Dialogue  10 :  2.5\n",
      "Dialogue  11 :  3.0\n",
      "Dialogue  12 :  2.8333333333333335\n",
      "Dialogue  13 :  3.0\n",
      "Dialogue  14 :  2.5\n",
      "Dialogue  15 :  2.6666666666666665\n",
      "Dialogue  16 :  3.0\n",
      "Dialogue  17 :  2.5\n",
      "\n",
      "Average score per language level\n",
      "Level  A1 :  2.4444444444444446\n",
      "Level  A2 :  2.1666666666666665\n",
      "Level  B1 :  2.7222222222222228\n",
      "Level  B2 :  2.722222222222222\n",
      "Level  C1 :  2.777777777777778\n",
      "Level  C2 :  2.722222222222222\n",
      "\n",
      "Total average score:  2.5925925925925926\n"
     ]
    }
   ],
   "source": [
    "ll_0_scores = load_scores('../../plays/evaluation/language_level/ll_0.csv')\n",
    "\n",
    "avg_dialogue_scores, total_avg = calcualate_metrics(ll_0_scores)\n",
    "\n",
    "avg_scores_per_ll = []\n",
    "for i in range(0, 18, 3):\n",
    "    avg_scores_per_ll.append(sum(avg_dialogue_scores[i:i+3])/3)\n",
    "\n",
    "print('Average scores per dialogue: ')\n",
    "for i, s in enumerate(avg_dialogue_scores):\n",
    "    print('Dialogue ', i, ': ', s )\n",
    "    \n",
    "print()\n",
    "print('Average score per language level')\n",
    "\n",
    "for s, ll in zip(avg_scores_per_ll, ['A1', 'A2', 'B1', 'B2', 'C1', 'C2']):\n",
    "    print('Level ', ll, ': ', s )\n",
    "\n",
    "print()\n",
    "print('Total average score: ', total_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average scores per dialogue: \n",
      "Dialogue  0 :  1.8333333333333333\n",
      "Dialogue  1 :  2.5\n",
      "Dialogue  2 :  2.6666666666666665\n",
      "Dialogue  3 :  2.5\n",
      "Dialogue  4 :  2.3333333333333335\n",
      "Dialogue  5 :  3.0\n",
      "Dialogue  6 :  2.1666666666666665\n",
      "Dialogue  7 :  2.1666666666666665\n",
      "Dialogue  8 :  1.8333333333333333\n",
      "Dialogue  9 :  2.8333333333333335\n",
      "Dialogue  10 :  2.0\n",
      "Dialogue  11 :  2.6666666666666665\n",
      "Dialogue  12 :  2.5\n",
      "Dialogue  13 :  3.0\n",
      "Dialogue  14 :  2.8333333333333335\n",
      "Dialogue  15 :  3.0\n",
      "Dialogue  16 :  2.5\n",
      "Dialogue  17 :  3.0\n",
      "\n",
      "Average score per language level\n",
      "Level  A1 :  2.3333333333333335\n",
      "Level  A2 :  2.611111111111111\n",
      "Level  B1 :  2.0555555555555554\n",
      "Level  B2 :  2.5\n",
      "Level  C1 :  2.777777777777778\n",
      "Level  C2 :  2.8333333333333335\n",
      "\n",
      "Total average score:  2.5185185185185186\n"
     ]
    }
   ],
   "source": [
    "ll_1_scores = load_scores('../../plays/evaluation/language_level/ll_1.csv')\n",
    "\n",
    "avg_dialogue_scores, total_avg = calcualate_metrics(ll_1_scores)\n",
    "\n",
    "avg_scores_per_ll = []\n",
    "for i in range(0, 18, 3):\n",
    "    avg_scores_per_ll.append(sum(avg_dialogue_scores[i:i+3])/3)\n",
    "\n",
    "print('Average scores per dialogue: ')\n",
    "for i, s in enumerate(avg_dialogue_scores):\n",
    "    print('Dialogue ', i, ': ', s )\n",
    "    \n",
    "print()\n",
    "print('Average score per language level')\n",
    "\n",
    "for s, ll in zip(avg_scores_per_ll, ['A1', 'A2', 'B1', 'B2', 'C1', 'C2']):\n",
    "    print('Level ', ll, ': ', s )\n",
    "\n",
    "print()\n",
    "print('Total average score: ', total_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average scores per dialogue: \n",
      "Dialogue  0 :  2.6666666666666665\n",
      "Dialogue  1 :  1.8333333333333333\n",
      "Dialogue  2 :  2.1666666666666665\n",
      "Dialogue  3 :  2.5\n",
      "Dialogue  4 :  3.0\n",
      "Dialogue  5 :  3.0\n",
      "Dialogue  6 :  2.6666666666666665\n",
      "Dialogue  7 :  2.8333333333333335\n",
      "Dialogue  8 :  2.0\n",
      "Dialogue  9 :  2.6666666666666665\n",
      "Dialogue  10 :  2.3333333333333335\n",
      "Dialogue  11 :  2.6666666666666665\n",
      "Dialogue  12 :  2.6666666666666665\n",
      "Dialogue  13 :  2.6666666666666665\n",
      "Dialogue  14 :  2.5\n",
      "Dialogue  15 :  2.8333333333333335\n",
      "Dialogue  16 :  2.6666666666666665\n",
      "Dialogue  17 :  2.6666666666666665\n",
      "\n",
      "Average score per language level\n",
      "Level  A1 :  2.222222222222222\n",
      "Level  A2 :  2.8333333333333335\n",
      "Level  B1 :  2.5\n",
      "Level  B2 :  2.5555555555555554\n",
      "Level  C1 :  2.611111111111111\n",
      "Level  C2 :  2.722222222222222\n",
      "\n",
      "Total average score:  2.574074074074074\n"
     ]
    }
   ],
   "source": [
    "ll_2_scores = load_scores('../../plays/evaluation/language_level/ll_2.csv')\n",
    "\n",
    "avg_dialogue_scores, total_avg = calcualate_metrics(ll_2_scores)\n",
    "\n",
    "avg_scores_per_ll = []\n",
    "for i in range(0, 18, 3):\n",
    "    avg_scores_per_ll.append(sum(avg_dialogue_scores[i:i+3])/3)\n",
    "\n",
    "print('Average scores per dialogue: ')\n",
    "for i, s in enumerate(avg_dialogue_scores):\n",
    "    print('Dialogue ', i, ': ', s )\n",
    "    \n",
    "print()\n",
    "print('Average score per language level')\n",
    "\n",
    "for s, ll in zip(avg_scores_per_ll, ['A1', 'A2', 'B1', 'B2', 'C1', 'C2']):\n",
    "    print('Level ', ll, ': ', s )\n",
    "\n",
    "print()\n",
    "print('Total average score: ', total_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average scores per dialogue: \n",
      "Dialogue  0 :  2.6666666666666665\n",
      "Dialogue  1 :  2.8333333333333335\n",
      "Dialogue  2 :  3.0\n",
      "Dialogue  3 :  2.6666666666666665\n",
      "Dialogue  4 :  2.0\n",
      "Dialogue  5 :  3.0\n",
      "Dialogue  6 :  2.5\n",
      "Dialogue  7 :  2.6666666666666665\n",
      "Dialogue  8 :  2.1666666666666665\n",
      "Dialogue  9 :  2.6666666666666665\n",
      "Dialogue  10 :  3.0\n",
      "Dialogue  11 :  3.0\n",
      "Dialogue  12 :  3.0\n",
      "Dialogue  13 :  3.0\n",
      "Dialogue  14 :  2.5\n",
      "Dialogue  15 :  2.6666666666666665\n",
      "Dialogue  16 :  1.8333333333333333\n",
      "Dialogue  17 :  2.5\n",
      "\n",
      "Average score per language level\n",
      "Level  A1 :  2.8333333333333335\n",
      "Level  A2 :  2.5555555555555554\n",
      "Level  B1 :  2.444444444444444\n",
      "Level  B2 :  2.888888888888889\n",
      "Level  C1 :  2.8333333333333335\n",
      "Level  C2 :  2.3333333333333335\n",
      "\n",
      "Total average score:  2.6481481481481484\n"
     ]
    }
   ],
   "source": [
    "ll_rf_0 = load_scores('../../plays/evaluation/language_level/ll_rf_0.csv')\n",
    "\n",
    "avg_dialogue_scores, total_avg = calcualate_metrics(ll_rf_0)\n",
    "\n",
    "avg_scores_per_ll = []\n",
    "for i in range(0, 18, 3):\n",
    "    avg_scores_per_ll.append(sum(avg_dialogue_scores[i:i+3])/3)\n",
    "\n",
    "print('Average scores per dialogue: ')\n",
    "for i, s in enumerate(avg_dialogue_scores):\n",
    "    print('Dialogue ', i, ': ', s )\n",
    "    \n",
    "print()\n",
    "print('Average score per language level')\n",
    "\n",
    "for s, ll in zip(avg_scores_per_ll, ['A1', 'A2', 'B1', 'B2', 'C1', 'C2']):\n",
    "    print('Level ', ll, ': ', s )\n",
    "\n",
    "print()\n",
    "print('Total average score: ', total_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average scores per dialogue: \n",
      "Dialogue  0 :  1.8333333333333333\n",
      "Dialogue  1 :  2.5\n",
      "Dialogue  2 :  2.8333333333333335\n",
      "Dialogue  3 :  3.0\n",
      "Dialogue  4 :  2.5\n",
      "Dialogue  5 :  3.0\n",
      "Dialogue  6 :  2.5\n",
      "Dialogue  7 :  3.0\n",
      "Dialogue  8 :  1.8333333333333333\n",
      "Dialogue  9 :  2.6666666666666665\n",
      "Dialogue  10 :  2.6666666666666665\n",
      "Dialogue  11 :  2.6666666666666665\n",
      "Dialogue  12 :  2.6666666666666665\n",
      "Dialogue  13 :  2.5\n",
      "Dialogue  14 :  3.0\n",
      "Dialogue  15 :  2.3333333333333335\n",
      "Dialogue  16 :  2.6666666666666665\n",
      "Dialogue  17 :  2.5\n",
      "\n",
      "Average score per language level\n",
      "Level  A1 :  2.388888888888889\n",
      "Level  A2 :  2.8333333333333335\n",
      "Level  B1 :  2.444444444444444\n",
      "Level  B2 :  2.6666666666666665\n",
      "Level  C1 :  2.722222222222222\n",
      "Level  C2 :  2.5\n",
      "\n",
      "Total average score:  2.5925925925925926\n"
     ]
    }
   ],
   "source": [
    "ll_rf_1 = load_scores('../../plays/evaluation/language_level/ll_rf_1.csv')\n",
    "\n",
    "avg_dialogue_scores, total_avg = calcualate_metrics(ll_rf_1)\n",
    "\n",
    "avg_scores_per_ll = []\n",
    "for i in range(0, 18, 3):\n",
    "    avg_scores_per_ll.append(sum(avg_dialogue_scores[i:i+3])/3)\n",
    "\n",
    "print('Average scores per dialogue: ')\n",
    "for i, s in enumerate(avg_dialogue_scores):\n",
    "    print('Dialogue ', i, ': ', s )\n",
    "    \n",
    "print()\n",
    "print('Average score per language level')\n",
    "\n",
    "for s, ll in zip(avg_scores_per_ll, ['A1', 'A2', 'B1', 'B2', 'C1', 'C2']):\n",
    "    print('Level ', ll, ': ', s )\n",
    "\n",
    "print()\n",
    "print('Total average score: ', total_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average scores per dialogue: \n",
      "Dialogue  0 :  2.5\n",
      "Dialogue  1 :  2.6666666666666665\n",
      "Dialogue  2 :  2.8333333333333335\n",
      "Dialogue  3 :  2.5\n",
      "Dialogue  4 :  2.5\n",
      "Dialogue  5 :  3.0\n",
      "Dialogue  6 :  2.5\n",
      "Dialogue  7 :  2.5\n",
      "Dialogue  8 :  3.0\n",
      "Dialogue  9 :  2.5\n",
      "Dialogue  10 :  2.6666666666666665\n",
      "Dialogue  11 :  2.6666666666666665\n",
      "Dialogue  12 :  2.6666666666666665\n",
      "Dialogue  13 :  2.6666666666666665\n",
      "Dialogue  14 :  2.5\n",
      "Dialogue  15 :  3.0\n",
      "Dialogue  16 :  2.0\n",
      "Dialogue  17 :  2.3333333333333335\n",
      "\n",
      "Average score per language level\n",
      "Level  A1 :  2.6666666666666665\n",
      "Level  A2 :  2.6666666666666665\n",
      "Level  B1 :  2.6666666666666665\n",
      "Level  B2 :  2.6111111111111107\n",
      "Level  C1 :  2.611111111111111\n",
      "Level  C2 :  2.4444444444444446\n",
      "\n",
      "Total average score:  2.611111111111111\n"
     ]
    }
   ],
   "source": [
    "ll_rf_2 = load_scores('../../plays/evaluation/language_level/ll_rf_2.csv')\n",
    "\n",
    "avg_dialogue_scores, total_avg = calcualate_metrics(ll_rf_2)\n",
    "\n",
    "avg_scores_per_ll = []\n",
    "for i in range(0, 18, 3):\n",
    "    avg_scores_per_ll.append(sum(avg_dialogue_scores[i:i+3])/3)\n",
    "\n",
    "print('Average scores per dialogue: ')\n",
    "for i, s in enumerate(avg_dialogue_scores):\n",
    "    print('Dialogue ', i, ': ', s )\n",
    "    \n",
    "print()\n",
    "print('Average score per language level')\n",
    "\n",
    "for s, ll in zip(avg_scores_per_ll, ['A1', 'A2', 'B1', 'B2', 'C1', 'C2']):\n",
    "    print('Level ', ll, ': ', s )\n",
    "\n",
    "print()\n",
    "print('Total average score: ', total_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average scores per dialogue: \n",
      "Dialogue  0 :  2.5\n",
      "Dialogue  1 :  2.6666666666666665\n",
      "Dialogue  2 :  2.8333333333333335\n",
      "Dialogue  3 :  2.5\n",
      "Dialogue  4 :  2.5\n",
      "Dialogue  5 :  3.0\n",
      "Dialogue  6 :  2.5\n",
      "Dialogue  7 :  2.5\n",
      "Dialogue  8 :  3.0\n",
      "Dialogue  9 :  2.5\n",
      "Dialogue  10 :  2.6666666666666665\n",
      "Dialogue  11 :  2.6666666666666665\n",
      "Dialogue  12 :  2.6666666666666665\n",
      "Dialogue  13 :  2.6666666666666665\n",
      "Dialogue  14 :  2.5\n",
      "Dialogue  15 :  3.0\n",
      "Dialogue  16 :  2.0\n",
      "Dialogue  17 :  2.3333333333333335\n",
      "\n",
      "Average score per language level\n",
      "Level  A1 :  2.6666666666666665\n",
      "Level  A2 :  2.6666666666666665\n",
      "Level  B1 :  2.6666666666666665\n",
      "Level  B2 :  2.6111111111111107\n",
      "Level  C1 :  2.611111111111111\n",
      "Level  C2 :  2.4444444444444446\n",
      "\n",
      "Total average score:  2.611111111111111\n"
     ]
    }
   ],
   "source": [
    "ll_rf_2 = load_scores('../../plays/evaluation/language_level/ll_rf_2.csv')\n",
    "\n",
    "avg_dialogue_scores, total_avg = calcualate_metrics(ll_rf_2)\n",
    "\n",
    "avg_scores_per_ll = []\n",
    "for i in range(0, 18, 3):\n",
    "    avg_scores_per_ll.append(sum(avg_dialogue_scores[i:i+3])/3)\n",
    "\n",
    "print('Average scores per dialogue: ')\n",
    "for i, s in enumerate(avg_dialogue_scores):\n",
    "    print('Dialogue ', i, ': ', s )\n",
    "    \n",
    "print()\n",
    "print('Average score per language level')\n",
    "\n",
    "for s, ll in zip(avg_scores_per_ll, ['A1', 'A2', 'B1', 'B2', 'C1', 'C2']):\n",
    "    print('Level ', ll, ': ', s )\n",
    "\n",
    "print()\n",
    "print('Total average score: ', total_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "internship",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
